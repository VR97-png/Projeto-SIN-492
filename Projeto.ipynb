{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VR97-png/Projeto-SIN-492/blob/main/Projeto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecFP82R6h61v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import keras\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import f_classif, SelectKBest, f_regression\n",
        "from keras.models import Sequential\n",
        "from keras.utils import normalize\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from scipy.stats import zscore\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchviz import make_dot, make_dot_from_trace\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a27x4TJ6h7C_"
      },
      "outputs": [],
      "source": [
        "parquet_url = '/content/dataset_SIN492.parquet'\n",
        "df = pd.read_parquet(parquet_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiFKq60rAwOj"
      },
      "outputs": [],
      "source": [
        "X = df.drop('target', axis=1)\n",
        "Y = df['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX8tBhjvh7Xd"
      },
      "outputs": [],
      "source": [
        " # Metodo ANOVA para achar as melhores features\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Seleção de features usando ANOVA\n",
        "k_best = SelectKBest(score_func=f_regression, k=6)\n",
        "X_train_selected = k_best.fit_transform(X_train, y_train)\n",
        "\n",
        "# Imprima as pontuações ANOVA para cada característica\n",
        "anova_scores = k_best.scores_\n",
        "selected_features = X_train.columns[k_best.get_support()]\n",
        "print(\"Features ANOVA:\")\n",
        "for feature in selected_features:\n",
        "    print(feature)\n",
        "    X_anova = X[selected_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ur9G5RCUW5i1"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_anova, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Definir o modelo\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Definir os hiperparâmetros para a busca em grade\n",
        "param_grid = {\n",
        "    'criterion': ['gini'],\n",
        "    'max_depth': range(1, 40),\n",
        "    'min_samples_split': range(2, 60),\n",
        "    'min_samples_leaf': range(1, 60),\n",
        "    'random_state': [42]\n",
        "}\n",
        "\n",
        "# Configurar a busca em grade\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=8)\n",
        "\n",
        "# Realizar a busca em grade\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Imprimir os melhores hiperparâmetros encontrados\n",
        "print(f'Os melhores hiperparâmetros encontrados foram: {grid_search.best_params_}')\n",
        "\n",
        "# Usar o melhor modelo para fazer previsões\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Avaliar a acurácia do modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'A acurácia do modelo é: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tXgxcN-wFWJ"
      },
      "outputs": [],
      "source": [
        "# Split do conjunto ANOVA de dados e rótulos\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_anova, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Criar um modelo de árvore de decisão para classificação\n",
        "clf = DecisionTreeClassifier(criterion='gini', max_depth=7, min_samples_split=47, min_samples_leaf=23, random_state=42)\n",
        "\n",
        "# Crie um objeto de validação cruzada KFold\n",
        "kf = KFold(n_splits=8, shuffle=True, random_state=42)\n",
        "\n",
        "# Realize a validação cruzada e obtenha as pontuações de acurácia\n",
        "cv_scores = cross_val_score(clf, X_train, y_train, cv=kf, scoring='accuracy')\n",
        "\n",
        "print(f'A pontuação média de validação cruzada é: {np.mean(cv_scores)}')\n",
        "\n",
        "# Treinar o modelo no conjunto de treinamento\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Avaliar a acurácia do modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f'A acurácia do modelo no conjunto de teste é: {accuracy}')\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plot_tree(clf, feature_names=X_anova.columns, class_names=list(map(str, clf.classes_)), filled=True, rounded=True)\n",
        "plt.show()\n",
        "\n",
        "# Gerar a matriz de confusão\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize a matriz de confusão usando seaborn\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Greens\", cbar=False, annot_kws={\"size\": 12})\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plotando o gráfico de perda\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmFJ-AjSh7c1"
      },
      "outputs": [],
      "source": [
        "# Normalização (z-score)\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "# Divida os dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crie um modelo sequencial\n",
        "model = Sequential()\n",
        "\n",
        "# Adicione camadas ao modelo\n",
        "model.add(Dense(9, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile o modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Converta y_train e y_test para representação categórica\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=2)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=2)\n",
        "\n",
        "# Treine o modelo\n",
        "history = model.fit(X_train, y_train, epochs=500, batch_size=32,\n",
        "                    validation_data=(X_test, y_test), verbose=0)\n",
        "\n",
        "# Avalie o modelo no conjunto de teste\n",
        "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "accuracy = accuracy_score(np.argmax(y_test, axis=-1), y_pred)\n",
        "print(f'A precisão do modelo é: {accuracy}')\n",
        "\n",
        "\n",
        "# Converta y_test de volta para rótulos de classe\n",
        "y_test_classes = np.argmax(y_test, axis=-1)\n",
        "\n",
        "# Crie a matriz de confusão\n",
        "conf_matrix = confusion_matrix(y_test_classes, y_pred)\n",
        "\n",
        "# Visualize a matriz de confusão usando seaborn\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, annot_kws={\"size\": 8})\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Obtendo os valores de perda e validação do histórico\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Plotando o gráfico de perda\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.plot(train_loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}